{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "from tensorflow.keras.layers import (Input,\n",
    "                                     Conv2D, \n",
    "                                     Concatenate,\n",
    "                                     BatchNormalization,\n",
    "                                     Lambda,\n",
    "                                     ReLU,\n",
    "                                     Reshape,\n",
    "                                     Add)\n",
    "from tensorflow.keras import backend as K\n",
    "print('TensorFlow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor=None,\n",
    "               filters=None,\n",
    "               kernel_size=None,\n",
    "               strides=1,\n",
    "               padding='same',\n",
    "               kernel_init='he_normal',\n",
    "               bias_init='zeros',\n",
    "               bn_act=True,\n",
    "               name_prefix=None):\n",
    "    \n",
    "    _x = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                padding=padding, strides=strides,\n",
    "                kernel_initializer=kernel_init,\n",
    "                bias_initializer=bias_init,\n",
    "                name='{}_conv_{}x{}'.format(name_prefix,\n",
    "                                            kernel_size,\n",
    "                                            kernel_size))(input_tensor)\n",
    "    if bn_act:\n",
    "        _x = BatchNormalization(\n",
    "            name='{}_bn'.format(name_prefix))(_x)\n",
    "        _x = ReLU(name='{}_relu'.format(name_prefix))(_x)\n",
    "    return _x\n",
    "\n",
    "\n",
    "def upsample_like(input_tensor, target_tensor, name=None):\n",
    "    _, fh, fw, _ = target_tensor.shape\n",
    "    _upsampled_tensor = tf.image.resize(input_tensor,\n",
    "                                        size=[fh, fw],\n",
    "                                        method='nearest', \n",
    "                                        name=name)\n",
    "    return _upsampled_tensor\n",
    "\n",
    "\n",
    "\n",
    "class Scale(tf.keras.layers.Layer):\n",
    "    def __init__(self, init_value=1.0, **kwargs):\n",
    "        super(Scale, self).__init__(**kwargs)\n",
    "        self.init_value = init_value\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.scale = \\\n",
    "            self.add_weight(name='scale',\n",
    "                            shape=[1],\n",
    "                            dtype=K.floatx(),\n",
    "                            trainable=True,\n",
    "                            initializer=Constant(value=self.init_value))\n",
    "\n",
    "    def call(self, x):\n",
    "        scaled_inputs = tf.multiply(self.scale, x)\n",
    "        return tf.exp(scaled_inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Scale, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCOS:\n",
    "    def __init__(self, config):\n",
    "        self._validate_config(config)\n",
    "        for attr in config:\n",
    "            setattr(self, attr, config[attr])\n",
    "        self._build_fpn()\n",
    "        self._build_model()\n",
    "        self._build_datasets()\n",
    "        self._build_optimizer()\n",
    "        self._build_callbacks()\n",
    "\n",
    "    def _validate_config(self, config):\n",
    "        attr_list = [\n",
    "            'mode',\n",
    "            'distribute_strategy',\n",
    "            'image_height',\n",
    "            'image_width',\n",
    "            'num_classes',\n",
    "            'data_dir',\n",
    "            'dataset_fn',\n",
    "            'batch_size',\n",
    "            'epochs',\n",
    "            'learning_rate',\n",
    "            'model_dir',\n",
    "            'tensorboard_log_dir'\n",
    "        ]\n",
    "        for attr in attr_list:\n",
    "            assert attr in config, 'Missing {} in config'.format(attr)\n",
    "\n",
    "    def _build_fpn(self):\n",
    "        '''\n",
    "            From the FPN paper, \"To start the iteration, we simply attach a\n",
    "            1×1 convolutional layer on C5 to produce the coarsest resolution\n",
    "            map. Finally, we append a 3×3 convolution on each merged map to\n",
    "            generate the final feature map, which is to reduce the aliasing\n",
    "            effect of upsampling. This final set of feature maps is called\n",
    "            {P2, P3, P4, P5}, corresponding to {C2, C3, C4, C5} that are\n",
    "            respectively of the same spatial sizes\".\n",
    "            From the FCOS paper, \"P6 and P7 are produced by applying one\n",
    "            convolutional layer with the stride being 2 on P5 and P6,\n",
    "            respectively\".\n",
    "        '''\n",
    "        with self.distribute_strategy.scope():\n",
    "            print('****Building FPN')\n",
    "            self._backbone = tf.keras.applications.ResNet50V2(\n",
    "                input_shape=[self.image_height, self.image_width, 3],\n",
    "                weights='imagenet',\n",
    "                include_top=False)\n",
    "            C5 = self._backbone.get_layer('post_relu').output\n",
    "            C4 = self._backbone.get_layer('conv4_block6_1_relu').output\n",
    "            C3 = self._backbone.get_layer('conv3_block4_1_relu').output\n",
    "\n",
    "            M5 = conv_block(C5, 256, 1, bn_act=False, name_prefix='C5')\n",
    "            P5 = conv_block(M5, 256, 3, bn_act=False, name_prefix='P5')\n",
    "            M5_upsampled = upsample_like(M5, C4, name='M5_upsampled')\n",
    "\n",
    "            M4 = conv_block(C4, 256, 1, bn_act=False, name_prefix='C4')\n",
    "            M4 = tf.keras.layers.Add(name='M4_M5_add')([M4, M5_upsampled])\n",
    "            P4 = conv_block(M4, 256, 3, bn_act=False, name_prefix='P4')\n",
    "            M4_upsampled = upsample_like(M4, C3, name='M4_upsampled')\n",
    "\n",
    "            M3 = conv_block(C3, 256, 1, bn_act=False, name_prefix='C3')\n",
    "            P3 = Add(name='M3_M4_add')([M3, M4_upsampled])\n",
    "            P3 = conv_block(P3, 256, 3, bn_act=False, name_prefix='P3')\n",
    "\n",
    "            P6 = conv_block(P5, 256, 3, 2, bn_act=False, name_prefix='P6')\n",
    "            P6_relu = ReLU(name='P6_relu')(P6)\n",
    "            P7 = conv_block(P6_relu, 256, 3, 2, bn_act=False, name_prefix='P7')\n",
    "\n",
    "            self._pyramid_features = {\n",
    "                'P3': P3,\n",
    "                'P4': P4,\n",
    "                'P5': P5,\n",
    "                'P6': P6,\n",
    "                'P7': P7\n",
    "            }\n",
    "\n",
    "    def _get_classification_head(self, p=0.01):\n",
    "        kernel_init = RandomNormal(0.0, 0.01)\n",
    "        bias_init = Constant(-np.log((1 - p) / p))\n",
    "\n",
    "        input_layer = Input(shape=[None, None, 256])\n",
    "        x = input_layer\n",
    "\n",
    "        for i in range(4):\n",
    "            x = conv_block(x, 256, 3, kernel_init=kernel_init,\n",
    "                           name_prefix='c_head_{}'.format(i))\n",
    "        classification_logits = conv_block(x, self.num_classes,\n",
    "                                           3, kernel_init=kernel_init,\n",
    "                                           bias_init=bias_init, bn_act=False,\n",
    "                                           name_prefix='cls_logits')\n",
    "        centerness_logits = conv_block(x, 1, 3,\n",
    "                                       kernel_init=kernel_init, bn_act=False,\n",
    "                                       name_prefix='ctr_logits')\n",
    "        classification_logits = Reshape(\n",
    "            target_shape=[-1, self.num_classes])(classification_logits)\n",
    "        centerness_logits = Reshape(target_shape=[-1, 1])(centerness_logits)\n",
    "\n",
    "        outputs = [classification_logits, centerness_logits]\n",
    "        return tf.keras.Model(inputs=[input_layer],\n",
    "                              outputs=[outputs],\n",
    "                              name='classification_head')\n",
    "\n",
    "    def _get_regression_head(self):\n",
    "        '''\n",
    "            From the FCOS paper, \"since the regression targets are always\n",
    "            positive we employ exp(x) to map any real number to (0, ∞) on\n",
    "            the top of the regression branch\"\n",
    "        '''\n",
    "        kernel_init = RandomNormal(0.0, 0.01)\n",
    "        input_layer = Input(shape=[None, None, 256])\n",
    "        x = input_layer\n",
    "\n",
    "        for i in range(4):\n",
    "            x = conv_block(x, 256, 3, kernel_init=kernel_init,\n",
    "                           name_prefix='r_head_{}'.format(i))\n",
    "        regression_logits = conv_block(x, 4, 3, kernel_init=kernel_init,\n",
    "                                       bn_act=False, name_prefix='reg_logits')\n",
    "        regression_logits = Reshape(target_shape=[-1, 4])(regression_logits)\n",
    "        return tf.keras.Model(inputs=[input_layer],\n",
    "                              outputs=[regression_logits],\n",
    "                              name='regression_head')\n",
    "\n",
    "    def _build_model(self):\n",
    "        with self.distribute_strategy.scope():\n",
    "            print('****Building FCOS')\n",
    "            self._classification_head = self._get_classification_head()\n",
    "            self._regression_head = self._get_regression_head()\n",
    "\n",
    "            self._classification_logits = []\n",
    "            self._centerness_logits = []\n",
    "            self._regression_logits = []\n",
    "\n",
    "            for i in range(3, 8):\n",
    "                feature = self._pyramid_features['P{}'.format(i)]\n",
    "                _cls_head_logits = self._classification_head(feature)\n",
    "                _reg_head_logits = self._regression_head(feature)\n",
    "                _reg_head_logits = \\\n",
    "                    Scale(init_value=1.0,\n",
    "                          name='P{}_reg_outputs'.format(i))(_reg_head_logits)\n",
    "\n",
    "                self._classification_logits.append(_cls_head_logits[0][0])\n",
    "                self._centerness_logits.append(_cls_head_logits[0][1])\n",
    "                self._regression_logits.append(_reg_head_logits)\n",
    "\n",
    "            self._classification_logits = Concatenate(\n",
    "                axis=1,\n",
    "                name='classification_outputs')(self._classification_logits)\n",
    "            self._centerness_logits = Concatenate(\n",
    "                axis=1, name='centerness_outputs')(self._centerness_logits)\n",
    "            self._regression_logits = Concatenate(\n",
    "                axis=1, name='regression_outputs')(self._regression_logits)\n",
    "\n",
    "            _image_input = self._backbone.input\n",
    "            outputs = [self._classification_logits,\n",
    "                       self._centerness_logits,\n",
    "                       self._regression_logits]\n",
    "            self.model = tf.keras.Model(\n",
    "                inputs=[_image_input], outputs=outputs, name='FCOS')\n",
    "            self.model.build([self.image_height, self.image_width, 3])\n",
    "\n",
    "    def _build_datasets(self):\n",
    "        print('****Building Datasets')\n",
    "        with self.distribute_strategy.scope():\n",
    "            self.train_dataset, self.val_dataset =  \\\n",
    "                self.dataset_fn(self.image_height,\n",
    "                                self.image_width,\n",
    "                                self.data_dir,\n",
    "                                self.batch_size)\n",
    "\n",
    "    def _build_callbacks(self):\n",
    "        print('****Setting Up Callbacks')\n",
    "        self.callbacks = [\n",
    "            TensorBoard(log_dir=self.tensorboard_log_dir),class FCOS:\n",
    "    def __init__(self, config):\n",
    "        self._validate_config(config)\n",
    "        for attr in config:\n",
    "            setattr(self, attr, config[attr])\n",
    "        self._build_fpn()\n",
    "        self._build_model()\n",
    "#         self._build_datasets()\n",
    "\n",
    "    def _validate_config(self, config):\n",
    "        attr_list = [\n",
    "            'mode',\n",
    "            'distribute_strategy',\n",
    "            'image_height',\n",
    "            'image_width',\n",
    "            'num_classes',\n",
    "            'data_dir',\n",
    "            'dataset_fn',\n",
    "            'batch_size',\n",
    "            'epochs',\n",
    "            'learning_rate',\n",
    "            'model_dir',\n",
    "            'tensorboard_log_dir'\n",
    "        ]\n",
    "        for attr in attr_list:\n",
    "            assert attr in config, 'Missing {} in config'.format(attr)\n",
    "\n",
    "    def _build_fpn(self):\n",
    "        '''\n",
    "            From the FPN paper, \"To start the iteration, we simply attach a\n",
    "            1×1 convolutional layer on C5 to produce the coarsest resolution\n",
    "            map. Finally, we append a 3×3 convolution on each merged map to\n",
    "            generate the final feature map, which is to reduce the aliasing\n",
    "            effect of upsampling. This final set of feature maps is called\n",
    "            {P2, P3, P4, P5}, corresponding to {C2, C3, C4, C5} that are\n",
    "            respectively of the same spatial sizes\".\n",
    "            From the FCOS paper, \"P6 and P7 are produced by applying one\n",
    "            convolutional layer with the stride being 2 on P5 and P6,\n",
    "            respectively\".\n",
    "        '''\n",
    "        with self.distribute_strategy.scope():\n",
    "            print('****Building FPN')\n",
    "            self._backbone = tf.keras.applications.ResNet50V2(\n",
    "                input_shape=[self.image_height, self.image_width, 3],\n",
    "                weights='imagenet',\n",
    "                include_top=False)\n",
    "            C5 = self._backbone.get_layer('post_relu').output\n",
    "            C4 = self._backbone.get_layer('conv4_block6_1_relu').output\n",
    "            C3 = self._backbone.get_layer('conv3_block4_1_relu').output\n",
    "\n",
    "            M5 = conv_block(C5, 256, 1, bn_act=False, name_prefix='C5')\n",
    "            P5 = conv_block(M5, 256, 3, bn_act=False, name_prefix='P5')\n",
    "            M5_upsampled = upsample_like(M5, C4, name='M5_upsampled')\n",
    "\n",
    "            M4 = conv_block(C4, 256, 1, bn_act=False, name_prefix='C4')\n",
    "            M4 = tf.keras.layers.Add(name='M4_M5_add')([M4, M5_upsampled])\n",
    "            P4 = conv_block(M4, 256, 3, bn_act=False, name_prefix='P4')\n",
    "            M4_upsampled = upsample_like(M4, C3, name='M4_upsampled')\n",
    "\n",
    "            M3 = conv_block(C3, 256, 1, bn_act=False, name_prefix='C3')\n",
    "            P3 = Add(name='M3_M4_add')([M3, M4_upsampled])\n",
    "            P3 = conv_block(P3, 256, 3, bn_act=False, name_prefix='P3')\n",
    "\n",
    "            P6 = conv_block(P5, 256, 3, 2, bn_act=False, name_prefix='P6')\n",
    "            P6_relu = ReLU(name='P6_relu')(P6)\n",
    "            P7 = conv_block(P6_relu, 256, 3, 2, bn_act=False, name_prefix='P7')\n",
    "\n",
    "            self._pyramid_features = {\n",
    "                'P3': P3,\n",
    "                'P4': P4,\n",
    "                'P5': P5,\n",
    "                'P6': P6,\n",
    "                'P7': P7\n",
    "            }\n",
    "\n",
    "    def _get_classification_head(self, p=0.01):\n",
    "        kernel_init = RandomNormal(0.0, 0.01)\n",
    "        bias_init = Constant(-np.log((1 - p) / p))\n",
    "\n",
    "        input_layer = Input(shape=[None, None, 256])\n",
    "        x = input_layer\n",
    "\n",
    "        for i in range(4):\n",
    "            x = conv_block(x, 256, 3, kernel_init=kernel_init,\n",
    "                           name_prefix='c_head_{}'.format(i))\n",
    "        classification_logits = conv_block(x, self.num_classes,\n",
    "                                           3, kernel_init=kernel_init,\n",
    "                                           bias_init=bias_init, bn_act=False,\n",
    "                                           name_prefix='cls_logits')\n",
    "        centerness_logits = conv_block(x, 1, 3,\n",
    "                                       kernel_init=kernel_init, bn_act=False,\n",
    "                                       name_prefix='ctr_logits')\n",
    "        classification_logits = Reshape(\n",
    "            target_shape=[-1, self.num_classes])(classification_logits)\n",
    "        centerness_logits = Reshape(target_shape=[-1, 1])(centerness_logits)\n",
    "\n",
    "        outputs = [classification_logits, centerness_logits]\n",
    "        return tf.keras.Model(inputs=[input_layer],\n",
    "                              outputs=[outputs],\n",
    "                              name='classification_head')\n",
    "\n",
    "    def _get_regression_head(self):\n",
    "        '''\n",
    "            From the FCOS paper, \"since the regression targets are always\n",
    "            positive we employ exp(x) to map any real number to (0, ∞) on\n",
    "            the top of the regression branch\"\n",
    "        '''\n",
    "        kernel_init = RandomNormal(0.0, 0.01)\n",
    "        input_layer = Input(shape=[None, None, 256])\n",
    "        x = input_layer\n",
    "\n",
    "        for i in range(4):\n",
    "            x = conv_block(x, 256, 3, kernel_init=kernel_init,\n",
    "                           name_prefix='r_head_{}'.format(i))\n",
    "        regression_logits = conv_block(x, 4, 3, kernel_init=kernel_init,\n",
    "                                       bn_act=False, name_prefix='reg_logits')\n",
    "        regression_logits = Reshape(target_shape=[-1, 4])(regression_logits)\n",
    "        return tf.keras.Model(inputs=[input_layer],\n",
    "                              outputs=[regression_logits],\n",
    "                              name='regression_head')\n",
    "\n",
    "    def _get_predictions_decoder(self):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def _build_model(self):\n",
    "        with self.distribute_strategy.scope():\n",
    "            print('****Building FCOS')\n",
    "            self._classification_head = self._get_classification_head()\n",
    "            self._regression_head = self._get_regression_head()\n",
    "\n",
    "            self._classification_logits = []\n",
    "            self._centerness_logits = []\n",
    "            self._regression_logits = []\n",
    "\n",
    "            for i in range(3, 8):\n",
    "                feature = self._pyramid_features['P{}'.format(i)]\n",
    "                _cls_head_logits = self._classification_head(feature)\n",
    "                _reg_head_logits = self._regression_head(feature)\n",
    "                _reg_head_logits = \\\n",
    "                    Scale(init_value=1.0,\n",
    "                          name='P{}_reg_outputs'.format(i))(_reg_head_logits)\n",
    "\n",
    "                self._classification_logits.append(_cls_head_logits[0][0])\n",
    "                self._centerness_logits.append(_cls_head_logits[0][1])\n",
    "                self._regression_logits.append(_reg_head_logits)\n",
    "\n",
    "            self._classification_logits = Concatenate(\n",
    "                axis=1,\n",
    "                name='classification_outputs')(self._classification_logits)\n",
    "            self._centerness_logits = Concatenate(\n",
    "                axis=1, name='centerness_outputs')(self._centerness_logits)\n",
    "            self._regression_logits = Concatenate(\n",
    "                axis=1, name='regression_outputs')(self._regression_logits)\n",
    "\n",
    "            _image_input = self._backbone.input\n",
    "            outputs = [self._classification_logits,\n",
    "                       self._centerness_logits,\n",
    "                       self._regression_logits]\n",
    "            self.model = tf.keras.Model(\n",
    "                inputs=[_image_input], outputs=outputs, name='FCOS')\n",
    "            self.model.build([self.image_height, self.image_width, 3])\n",
    "\n",
    "    def _build_datasets(self):\n",
    "        print('****Building Datasets')\n",
    "        with self.distribute_strategy.scope():\n",
    "            self.train_dataset, self.val_dataset =  \\\n",
    "                self.dataset_fn(self.image_height,\n",
    "                                self.image_width,\n",
    "                                self.data_dir,\n",
    "                                self.batch_size)\n",
    "\n",
    "    def __call__(self):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def _classification_loss(self, alpha=0.25, gamma=2):\n",
    "        # TODO\n",
    "        #   a) mask negative locations\n",
    "        #   b) normalize loss value\n",
    "        def focal_loss(y_true, y_pred):\n",
    "            y_true = tf.one_hot(\n",
    "                tf.cast(y_true, dtype=tf.int32), depth=self.num_classes + 1)\n",
    "            y_true = y_true[:, :, 1:]\n",
    "            y_pred_ = tf.sigmoid(y_pred)\n",
    "\n",
    "            at = alpha * y_true + (1 - y_true) * (1 - alpha)\n",
    "            pt = y_true * y_pred_ + (1 - y_true) * (1 - y_pred_)\n",
    "            f_loss = at * \\\n",
    "                tf.pow(1 - pt, gamma) * \\\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    labels=y_true, logits=y_pred)\n",
    "            return f_loss\n",
    "        return focal_loss\n",
    "\n",
    "    def _centerness_loss(self, labels, logits):\n",
    "        # TODO\n",
    "        #   a) mask negative locations\n",
    "        #   b) normalize loss value\n",
    "        bce_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits)\n",
    "        return bce_loss\n",
    "\n",
    "    def _regression_loss(self, labels, logits):\n",
    "        # TODO\n",
    "        #   a) IOU loss\n",
    "        #   b) mask negative locations\n",
    "        #   c) normalize loss value\n",
    "        pass\n",
    "            ModelCheckpoint(filepath=self.model_dir + '/ckpt-{epoch:02d}',\n",
    "                            monitor='val_loss',\n",
    "                            save_weights_only=True,\n",
    "                            save_best_only=True)\n",
    "        ]\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        print('****Setting Up Optimizer')\n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr=self.learning_rate)\n",
    "\n",
    "    def _classification_loss(self, alpha=0.25, gamma=2):\n",
    "        # TODO\n",
    "        #   a) mask negative locations\n",
    "        #   b) normalize loss value\n",
    "        def focal_loss(y_true, y_pred):\n",
    "            y_true = tf.one_hot(\n",
    "                tf.cast(y_true, dtype=tf.int32), depth=self.num_classes + 1)\n",
    "            y_true = y_true[:, :, 1:]\n",
    "            y_pred_ = tf.sigmoid(y_pred)\n",
    "\n",
    "            at = alpha * y_true + (1 - y_true) * (1 - alpha)\n",
    "            pt = y_true * y_pred_ + (1 - y_true) * (1 - y_pred_)\n",
    "            f_loss = at * \\\n",
    "                tf.pow(1 - pt, gamma) * \\\n",
    "                tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    labels=y_true, logits=y_pred)\n",
    "            return f_loss\n",
    "        return focal_loss\n",
    "\n",
    "    def _centerness_loss(self, labels, logits):\n",
    "        # TODO\n",
    "        #   a) mask negative locations\n",
    "        #   b) normalize loss value\n",
    "        bce_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits)\n",
    "        return bce_loss\n",
    "\n",
    "    def _regression_loss(self, labels, logits):\n",
    "        # TODO\n",
    "        #   a) IOU loss\n",
    "        #   b) mask negative locations\n",
    "        #   c) normalize loss value\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        loss_dict = {\n",
    "            'classification_outputs': self._classification_loss(alpha=0.25,\n",
    "                                                                gamma=2),\n",
    "            'centerness_outputs': self._centerness_loss,\n",
    "            'regression_outputs': self._regression_loss\n",
    "        }\n",
    "        with self.distribute_strategy.scope():\n",
    "            self.model.compile(optimizer=self.optimizer,\n",
    "                               loss=loss_dict)\n",
    "            # self.model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'mode': 'train',\n",
    "    'distribute_strategy': tf.distribute.OneDeviceStrategy(device='/cpu:0'),\n",
    "    'image_height': 720,\n",
    "    'image_width': 1280,\n",
    "    'num_classes': 10,\n",
    "    'dataset_fn': None,\n",
    "    'data_dir': '../tfrecords',\n",
    "    'batch_size': 4,\n",
    "    'epochs': 250,\n",
    "    'learning_rate': 1e-4,\n",
    "    'model_dir': 'model_files',\n",
    "    'tensorboard_log_dir': 'logs'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Building FPN\n",
      "****Building FCOS\n"
     ]
    }
   ],
   "source": [
    "fcos = FCOS(config)\n",
    "dummy_tensor = tf.random.normal(shape=[1, 720, 1280, 3])\n",
    "dummy_output = fcos.model(dummy_tensor, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=25365, shape=(1, 19220, 10), dtype=float32, numpy=\n",
       " array([[[-4.5939984, -4.5933757, -4.6110363, ..., -4.5984144,\n",
       "          -4.601757 , -4.583133 ],\n",
       "         [-4.599728 , -4.5907536, -4.6028256, ..., -4.6014833,\n",
       "          -4.602731 , -4.5780544],\n",
       "         [-4.600538 , -4.5935106, -4.601371 , ..., -4.6003246,\n",
       "          -4.603682 , -4.5814824],\n",
       "         ...,\n",
       "         [-4.5972333, -4.5994215, -4.592283 , ..., -4.596968 ,\n",
       "          -4.5902376, -4.603656 ],\n",
       "         [-4.5970044, -4.5971713, -4.591698 , ..., -4.5915704,\n",
       "          -4.587244 , -4.5974708],\n",
       "         [-4.5913167, -4.592581 , -4.587546 , ..., -4.5954504,\n",
       "          -4.5853906, -4.597687 ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=25363, shape=(1, 19220, 1), dtype=float32, numpy=\n",
       " array([[[-0.00088442],\n",
       "         [-0.0060561 ],\n",
       "         [-0.00249656],\n",
       "         ...,\n",
       "         [-0.01048212],\n",
       "         [-0.00427284],\n",
       "         [-0.01161309]]], dtype=float32)>,\n",
       " <tf.Tensor: id=25361, shape=(1, 19220, 4), dtype=float32, numpy=\n",
       " array([[[1.0016294 , 0.9960024 , 0.99630183, 0.99011797],\n",
       "         [1.0163672 , 0.99960005, 0.99385214, 0.9889543 ],\n",
       "         [1.0120755 , 0.99241763, 0.9912596 , 0.9893112 ],\n",
       "         ...,\n",
       "         [1.0214987 , 1.0145433 , 1.0035706 , 0.9933048 ],\n",
       "         [1.010926  , 1.0107565 , 1.0062639 , 0.98948693],\n",
       "         [1.0116392 , 0.9985297 , 0.9925391 , 0.9982908 ]]], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'classification_outputs_1/Identity:0' shape=(None, None, 10) dtype=float32>,\n",
       " <tf.Tensor 'centerness_outputs_1/Identity:0' shape=(None, None, 1) dtype=float32>,\n",
       " <tf.Tensor 'regression_outputs_1/Identity:0' shape=(None, None, 4) dtype=float32>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcos.model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"regression_head\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, None, None, 256)] 0         \n",
      "_________________________________________________________________\n",
      "r_head_0_conv_3x3 (Conv2D)   multiple                  590080    \n",
      "_________________________________________________________________\n",
      "r_head_0_bn (BatchNormalizat multiple                  1024      \n",
      "_________________________________________________________________\n",
      "r_head_0_relu (ReLU)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "r_head_1_conv_3x3 (Conv2D)   multiple                  590080    \n",
      "_________________________________________________________________\n",
      "r_head_1_bn (BatchNormalizat multiple                  1024      \n",
      "_________________________________________________________________\n",
      "r_head_1_relu (ReLU)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "r_head_2_conv_3x3 (Conv2D)   multiple                  590080    \n",
      "_________________________________________________________________\n",
      "r_head_2_bn (BatchNormalizat multiple                  1024      \n",
      "_________________________________________________________________\n",
      "r_head_2_relu (ReLU)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "r_head_3_conv_3x3 (Conv2D)   multiple                  590080    \n",
      "_________________________________________________________________\n",
      "r_head_3_bn (BatchNormalizat multiple                  1024      \n",
      "_________________________________________________________________\n",
      "r_head_3_relu (ReLU)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "reg_logits_conv_3x3 (Conv2D) multiple                  9220      \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, None, 4)           0         \n",
      "=================================================================\n",
      "Total params: 2,373,636\n",
      "Trainable params: 2,371,588\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "Model: \"classification_head\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c_head_0_conv_3x3 (Conv2D)      multiple             590080      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c_head_0_bn (BatchNormalization multiple             1024        c_head_0_conv_3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "c_head_0_relu (ReLU)            multiple             0           c_head_0_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c_head_1_conv_3x3 (Conv2D)      multiple             590080      c_head_0_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c_head_1_bn (BatchNormalization multiple             1024        c_head_1_conv_3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "c_head_1_relu (ReLU)            multiple             0           c_head_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c_head_2_conv_3x3 (Conv2D)      multiple             590080      c_head_1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c_head_2_bn (BatchNormalization multiple             1024        c_head_2_conv_3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "c_head_2_relu (ReLU)            multiple             0           c_head_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c_head_3_conv_3x3 (Conv2D)      multiple             590080      c_head_2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c_head_3_bn (BatchNormalization multiple             1024        c_head_3_conv_3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "c_head_3_relu (ReLU)            multiple             0           c_head_3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cls_logits_conv_3x3 (Conv2D)    multiple             23050       c_head_3_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ctr_logits_conv_3x3 (Conv2D)    multiple             2305        c_head_3_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, None, 10)     0           cls_logits_conv_3x3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, None, 1)      0           ctr_logits_conv_3x3[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 2,389,771\n",
      "Trainable params: 2,387,723\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcos._regression_head.summary(), fcos._classification_head.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P3': <tf.Tensor 'P3_conv_3x3_1/Identity:0' shape=(None, 90, 160, 256) dtype=float32>,\n",
       " 'P4': <tf.Tensor 'P4_conv_3x3_1/Identity:0' shape=(None, 45, 80, 256) dtype=float32>,\n",
       " 'P5': <tf.Tensor 'P5_conv_3x3_1/Identity:0' shape=(None, 23, 40, 256) dtype=float32>,\n",
       " 'P6': <tf.Tensor 'P6_conv_3x3_1/Identity:0' shape=(None, 12, 20, 256) dtype=float32>,\n",
       " 'P7': <tf.Tensor 'P7_conv_3x3_1/Identity:0' shape=(None, 6, 10, 256) dtype=float32>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcos._pyramid_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FCOS\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 720, 1280, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 726, 1286, 3) 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 360, 640, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 362, 642, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 180, 320, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 180, 320, 64) 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 180, 320, 64) 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 180, 320, 64) 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 180, 320, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 180, 320, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 182, 322, 64) 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 180, 320, 64) 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 180, 320, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 180, 320, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 180, 320, 256 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 180, 320, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 180, 320, 256 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 180, 320, 256 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 180, 320, 256 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 180, 320, 64) 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 180, 320, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 180, 320, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 182, 322, 64) 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 180, 320, 64) 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 180, 320, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 180, 320, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 180, 320, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 180, 320, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 180, 320, 256 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 180, 320, 256 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 180, 320, 64) 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 180, 320, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 180, 320, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 182, 322, 64) 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 90, 160, 64)  36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 90, 160, 64)  256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 90, 160, 64)  0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 90, 160, 256) 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 90, 160, 256) 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 90, 160, 256) 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 90, 160, 256) 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 90, 160, 256) 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 90, 160, 128) 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 90, 160, 128) 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 92, 162, 128) 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 90, 160, 128) 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 90, 160, 128) 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 90, 160, 512) 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 90, 160, 512) 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 90, 160, 512) 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 90, 160, 512) 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 90, 160, 512) 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 90, 160, 128) 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 90, 160, 128) 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 92, 162, 128) 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 90, 160, 128) 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 90, 160, 128) 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 90, 160, 512) 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 90, 160, 512) 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 90, 160, 512) 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 90, 160, 512) 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 90, 160, 128) 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 90, 160, 128) 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 92, 162, 128) 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 90, 160, 128) 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 90, 160, 128) 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 90, 160, 512) 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 90, 160, 512) 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 90, 160, 512) 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 90, 160, 512) 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 90, 160, 128) 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 90, 160, 128) 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 92, 162, 128) 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 45, 80, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 45, 80, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 45, 80, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 45, 80, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 45, 80, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 45, 80, 512)  0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 45, 80, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 45, 80, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 45, 80, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 45, 80, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 45, 80, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 45, 80, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 45, 80, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 45, 80, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 45, 80, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 45, 80, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 45, 80, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 45, 80, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 45, 80, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 45, 80, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 45, 80, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 45, 80, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 45, 80, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 45, 80, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 45, 80, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 45, 80, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 45, 80, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 45, 80, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 45, 80, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 45, 80, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 45, 80, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 45, 80, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 45, 80, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 45, 80, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 45, 80, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 45, 80, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 45, 80, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 45, 80, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 45, 80, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 45, 80, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 45, 80, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 45, 80, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 45, 80, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 45, 80, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 45, 80, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 45, 80, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 45, 80, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 45, 80, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 45, 80, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 45, 80, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 45, 80, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 23, 40, 256)  589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 23, 40, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 23, 40, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 23, 40, 1024) 0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 23, 40, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 23, 40, 1024) 0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 23, 40, 1024) 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 23, 40, 1024) 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 23, 40, 512)  524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 23, 40, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 25, 42, 512)  0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 23, 40, 512)  2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 23, 40, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 23, 40, 2048) 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 23, 40, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 23, 40, 2048) 0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 23, 40, 2048) 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 23, 40, 2048) 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 23, 40, 512)  1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 23, 40, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 25, 42, 512)  0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 23, 40, 512)  2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 23, 40, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 23, 40, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 23, 40, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 23, 40, 2048) 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 23, 40, 2048) 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 23, 40, 512)  1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 23, 40, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 25, 42, 512)  0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 23, 40, 512)  2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 23, 40, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 23, 40, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 23, 40, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 23, 40, 2048) 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 23, 40, 2048) 0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "C5_conv_1x1 (Conv2D)            (None, 23, 40, 256)  524544      post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "C4_conv_1x1 (Conv2D)            (None, 45, 80, 256)  65792       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_M5_upsampled_1/Resi [(None, 45, 80, 256) 0           C5_conv_1x1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "M4_M5_add (Add)                 (None, 45, 80, 256)  0           C4_conv_1x1[0][0]                \n",
      "                                                                 tf_op_layer_M5_upsampled_1/Resize\n",
      "__________________________________________________________________________________________________\n",
      "P5_conv_3x3 (Conv2D)            (None, 23, 40, 256)  590080      C5_conv_1x1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "C3_conv_1x1 (Conv2D)            (None, 90, 160, 256) 33024       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_M4_upsampled_1/Resi [(None, 90, 160, 256 0           M4_M5_add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P6_conv_3x3 (Conv2D)            (None, 12, 20, 256)  590080      P5_conv_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "M3_M4_add (Add)                 (None, 90, 160, 256) 0           C3_conv_1x1[0][0]                \n",
      "                                                                 tf_op_layer_M4_upsampled_1/Resize\n",
      "__________________________________________________________________________________________________\n",
      "P6_relu (ReLU)                  (None, 12, 20, 256)  0           P6_conv_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "P3_conv_3x3 (Conv2D)            (None, 90, 160, 256) 590080      M3_M4_add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P4_conv_3x3 (Conv2D)            (None, 45, 80, 256)  590080      M4_M5_add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P7_conv_3x3 (Conv2D)            (None, 6, 10, 256)   590080      P6_relu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "regression_head (Model)         (None, None, 4)      2373636     P3_conv_3x3[0][0]                \n",
      "                                                                 P4_conv_3x3[0][0]                \n",
      "                                                                 P5_conv_3x3[0][0]                \n",
      "                                                                 P6_conv_3x3[0][0]                \n",
      "                                                                 P7_conv_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "classification_head (Model)     [[(None, None, 10),  2389771     P3_conv_3x3[0][0]                \n",
      "                                                                 P4_conv_3x3[0][0]                \n",
      "                                                                 P5_conv_3x3[0][0]                \n",
      "                                                                 P6_conv_3x3[0][0]                \n",
      "                                                                 P7_conv_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "P3_reg_outputs (Scale)          (None, None, 4)      1           regression_head[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "P4_reg_outputs (Scale)          (None, None, 4)      1           regression_head[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "P5_reg_outputs (Scale)          (None, None, 4)      1           regression_head[3][0]            \n",
      "__________________________________________________________________________________________________\n",
      "P6_reg_outputs (Scale)          (None, None, 4)      1           regression_head[4][0]            \n",
      "__________________________________________________________________________________________________\n",
      "P7_reg_outputs (Scale)          (None, None, 4)      1           regression_head[5][0]            \n",
      "__________________________________________________________________________________________________\n",
      "classification_outputs (Concate (None, None, 10)     0           classification_head[1][0]        \n",
      "                                                                 classification_head[2][0]        \n",
      "                                                                 classification_head[3][0]        \n",
      "                                                                 classification_head[4][0]        \n",
      "                                                                 classification_head[5][0]        \n",
      "__________________________________________________________________________________________________\n",
      "centerness_outputs (Concatenate (None, None, 1)      0           classification_head[1][1]        \n",
      "                                                                 classification_head[2][1]        \n",
      "                                                                 classification_head[3][1]        \n",
      "                                                                 classification_head[4][1]        \n",
      "                                                                 classification_head[5][1]        \n",
      "__________________________________________________________________________________________________\n",
      "regression_outputs (Concatenate (None, None, 4)      0           P3_reg_outputs[0][0]             \n",
      "                                                                 P4_reg_outputs[0][0]             \n",
      "                                                                 P5_reg_outputs[0][0]             \n",
      "                                                                 P6_reg_outputs[0][0]             \n",
      "                                                                 P7_reg_outputs[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 31,901,972\n",
      "Trainable params: 31,852,436\n",
      "Non-trainable params: 49,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fcos.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
