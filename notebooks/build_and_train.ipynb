{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor=None,\n",
    "               filters=None,\n",
    "               kernel_size=None,\n",
    "               padding='same',\n",
    "               strides=1,\n",
    "               w_init='he_normal',\n",
    "               bn_act=True,\n",
    "               name_prefix=None):\n",
    "    _x = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                padding=padding,\n",
    "                                strides=strides,\n",
    "                                kernel_initializer=w_init,\n",
    "                                name='{}_conv_{}x{}'.format(name_prefix,\n",
    "                                                            kernel_size,\n",
    "                                                            kernel_size))(input_tensor)\n",
    "    if bn_act:\n",
    "        _x = tf.keras.layers.BatchNormalization(\n",
    "            name='{}_bn'.format(name_prefix))(_x)\n",
    "        _x = tf.keras.layers.ReLU(name='{}_relu'.format(name_prefix))(_x)\n",
    "    return _x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN:\n",
    "    def __init__(H=800, W=1024):\n",
    "    self.backbone = tf.keras.applications.ResNet50V2(\n",
    "        input_shape=[H, W, 3], weights='imagenet', include_top=False)\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_pyramid_features():\n",
    "        '''\n",
    "            From the FPN paper, \"To start the iteration, we simply attach a\n",
    "            1×1 convolutional layer on C5 to produce the coarsest resolution map.\n",
    "            Finally, we append a 3×3 convolution on each merged map to generate\n",
    "            the final feature map, which is to reduce the aliasing effect of\n",
    "            upsampling. This final set of feature maps is called\n",
    "            {P2, P3, P4, P5}, corresponding to {C2, C3, C4, C5} that are\n",
    "            respectively of the same spatial sizes\".\n",
    "            From the FCOS paper, \"P6 and P7 are produced by applying one\n",
    "            convolutional layer with the stride being 2 on P5 and P6, respectively\".\n",
    "        '''\n",
    "        C5 = backbone.get_layer('post_relu').output\n",
    "        C4 = backbone.get_layer('conv4_block6_1_relu').output\n",
    "        C3 = backbone.get_layer('conv3_block4_1_relu').output\n",
    "\n",
    "        M5 = conv_block(C5, filters=256, kernel_size=1,\n",
    "                        bn_act=False, name_prefix='C5')\n",
    "        P5 = conv_block(M5, filters=256, kernel_size=3,\n",
    "                        bn_act=False, name_prefix='P5')\n",
    "        M5_upsampled = tf.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    interpolation='nearest',\n",
    "                                                    name='M5_upsampled')(M5)\n",
    "\n",
    "        M4 = conv_block(C4, filters=256, kernel_size=1,\n",
    "                        bn_act=False, name_prefix='C4')\n",
    "        M4 = tf.keras.layers.Add(name='M4_M5_add')([M4, M5_upsampled])\n",
    "        P4 = conv_block(M4, filters=256, kernel_size=3,\n",
    "                        bn_act=False, name_prefix='P4')\n",
    "        M4_upsampled = tf.keras.layers.UpSampling2D(size=(2, 2),\n",
    "                                                    interpolation='nearest',\n",
    "                                                    name='M4_upsampled')(M4)\n",
    "\n",
    "        M3 = conv_block(C3, filters=256, kernel_size=1,\n",
    "                        bn_act=False, name_prefix='C3')\n",
    "        P3 = tf.keras.layers.Add(name='M3_M4_add')([M3, M4_upsampled])\n",
    "        P3 = conv_block(P3, filters=256, kernel_size=3,\n",
    "                        bn_act=False, name_prefix='P3')\n",
    "\n",
    "        P6 = conv_block(P5, filters=256, kernel_size=3,\n",
    "                        strides=2, bn_act=False, name_prefix='P6')\n",
    "        P6_relu = tf.keras.layers.ReLU(name='P6_relu')(P6)\n",
    "        P7 = conv_block(P6_relu, filters=256, kernel_size=3,\n",
    "                        strides=2, bn_act=False, name_prefix='P7')\n",
    "        return {\n",
    "            'P3': P3,\n",
    "            'P4': P4,\n",
    "            'P5': P5,\n",
    "            'P6': P6,\n",
    "            'P7': P7,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
