{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "from tensorflow.keras.layers import (Input,\n",
    "                                     Conv2D, \n",
    "                                     BatchNormalization,\n",
    "                                     Lambda,\n",
    "                                     ReLU, \n",
    "                                     Add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor=None,\n",
    "               filters=None,\n",
    "               kernel_size=None,\n",
    "               strides=1,\n",
    "               padding='same',\n",
    "               kernel_init='he_normal',\n",
    "               bias_init='zeros',\n",
    "               bn_act=True,\n",
    "               name_prefix=None):\n",
    "    \n",
    "    _x = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                padding=padding, strides=strides,\n",
    "                kernel_initializer=kernel_init,\n",
    "                bias_initializer=bias_init,\n",
    "                name='{}_conv_{}x{}'.format(name_prefix,\n",
    "                                            kernel_size,\n",
    "                                            kernel_size))(input_tensor)\n",
    "    if bn_act:\n",
    "        _x = BatchNormalization(\n",
    "            name='{}_bn'.format(name_prefix))(_x)\n",
    "        _x = ReLU(name='{}_relu'.format(name_prefix))(_x)\n",
    "    return _x\n",
    "\n",
    "\n",
    "def upsample_like(input_tensor, target_tensor, name=None):\n",
    "    _, fh, fw, _ = target_tensor.shape\n",
    "    _upsampled_tensor = tf.image.resize(input_tensor,\n",
    "                                        size=[fh, fw],\n",
    "                                        method='nearest', \n",
    "                                        name=name)\n",
    "    return _upsampled_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCOS:\n",
    "    def __init__(self, config):\n",
    "        self._validate_config(config)\n",
    "        for attr in config:\n",
    "            setattr(self, attr, config[attr])\n",
    "        self._build_fpn()\n",
    "        self._build_model()\n",
    "\n",
    "    def _validate_config(self, config):\n",
    "        attr_list = [\n",
    "            'mode',\n",
    "            'distribute_strategy',\n",
    "            'image_height',\n",
    "            'image_width',\n",
    "            'num_classes',\n",
    "            'dataset',\n",
    "            'epochs',\n",
    "            'learning_rate',\n",
    "            'model_dir',\n",
    "            'tensorboard_log_dir'\n",
    "        ]\n",
    "        for attr in attr_list:\n",
    "            assert attr in config, 'Missing {} in config'.format(attr)\n",
    "\n",
    "    def _build_fpn(self):\n",
    "        '''\n",
    "            From the FPN paper, \"To start the iteration, we simply attach a\n",
    "            1×1 convolutional layer on C5 to produce the coarsest resolution map.\n",
    "            Finally, we append a 3×3 convolution on each merged map to generate\n",
    "            the final feature map, which is to reduce the aliasing effect of\n",
    "            upsampling. This final set of feature maps is called\n",
    "            {P2, P3, P4, P5}, corresponding to {C2, C3, C4, C5} that are\n",
    "            respectively of the same spatial sizes\".\n",
    "            From the FCOS paper, \"P6 and P7 are produced by applying one\n",
    "            convolutional layer with the stride being 2 on P5 and P6, respectively\".\n",
    "        '''\n",
    "        with self.distribute_strategy.scope():\n",
    "            print('****Building FPN')\n",
    "            self._backbone = tf.keras.applications.ResNet50V2(\n",
    "                input_shape=[self.image_height, self.image_width, 3],\n",
    "                weights='imagenet',\n",
    "                include_top=False)\n",
    "            C5 = self._backbone.get_layer('post_relu').output\n",
    "            C4 = self._backbone.get_layer('conv4_block6_1_relu').output\n",
    "            C3 = self._backbone.get_layer('conv3_block4_1_relu').output\n",
    "\n",
    "            M5 = conv_block(C5, 256, 1, bn_act=False, name_prefix='C5')\n",
    "            P5 = conv_block(M5, 256, 3, bn_act=False, name_prefix='P5')\n",
    "            M5_upsampled = upsample_like(M5, C4, name='M5_upsampled')\n",
    "\n",
    "            M4 = conv_block(C4, 256, 1, bn_act=False, name_prefix='C4')\n",
    "            M4 = tf.keras.layers.Add(name='M4_M5_add')([M4, M5_upsampled])\n",
    "            P4 = conv_block(M4, 256, 3, bn_act=False, name_prefix='P4')\n",
    "            M4_upsampled = upsample_like(M4, C3, name='M4_upsampled')\n",
    "\n",
    "\n",
    "            M3 = conv_block(C3, 256, 1, bn_act=False, name_prefix='C3')\n",
    "            P3 = Add(name='M3_M4_add')([M3, M4_upsampled])\n",
    "            P3 = conv_block(P3, 256, 3, bn_act=False, name_prefix='P3')\n",
    "\n",
    "            P6 = conv_block(P5, 256, 3, 2, bn_act=False, name_prefix='P6')\n",
    "            P6_relu = ReLU(name='P6_relu')(P6)\n",
    "            P7 = conv_block(P6_relu, 256, 3, 2, bn_act=False, name_prefix='P7')\n",
    "\n",
    "            self._pyramid_features = {\n",
    "                'P3': P3,\n",
    "                'P4': P4,\n",
    "                'P5': P5,\n",
    "                'P6': P6,\n",
    "                'P7': P7\n",
    "            }\n",
    "\n",
    "    def _get_classification_head(self, p=0.01):\n",
    "        kernel_init = RandomNormal(0.0, 0.01)\n",
    "        bias_init = Constant(-np.log((1 - p) / p))\n",
    "\n",
    "        input_layer = Input(shape=[None, None, 256])\n",
    "        x = input_layer\n",
    "\n",
    "        for i in range(4):\n",
    "            x = conv_block(x, 256, 3, kernel_init=kernel_init,\n",
    "                           name_prefix='c_head_{}'.format(i))\n",
    "        classification_logits = conv_block(x, self.num_classes,\n",
    "                                           3, kernel_init=kernel_init,\n",
    "                                           bias_init=bias_init, bn_act=False,\n",
    "                                           name_prefix='cls_logits')\n",
    "        centerness_logits = conv_block(x, 1, 3,\n",
    "                                       kernel_init=kernel_init, bn_act=False,\n",
    "                                       name_prefix='ctr_logits')\n",
    "        outputs = [classification_logits, centerness_logits]\n",
    "        return tf.keras.Model(inputs=[input_layer],\n",
    "                              outputs=[outputs],\n",
    "                              name='classification_head')\n",
    "\n",
    "    def _get_regression_head(self):\n",
    "        '''\n",
    "            From the FCOS paper, \"since the regression targets are always positive\n",
    "            we employ exp(x) to map any real number to (0, ∞) on the top of the\n",
    "            regression branch\"\n",
    "        '''\n",
    "        kernel_init = RandomNormal(0.0, 0.01)\n",
    "        input_layer = Input(shape=[None, None, 256])\n",
    "        x = input_layer\n",
    "\n",
    "        for i in range(4):\n",
    "            x = conv_block(x, 256, 3, kernel_init=kernel_init,\n",
    "                           name_prefix='r_head_{}'.format(i))\n",
    "        regression_logits = conv_block(x, 4, 3, kernel_init=kernel_init,\n",
    "                                       bn_act=False, name_prefix='reg_logits')\n",
    "        regression_logits = Lambda(tf.exp, name='reg_logits')(regression_logits)\n",
    "        return tf.keras.Model(inputs=[input_layer],\n",
    "                              outputs=[regression_logits],\n",
    "                              name='regression_head')\n",
    "\n",
    "    def _build_model(self):\n",
    "        with self.distribute_strategy.scope():\n",
    "            print('****Building FCOS')\n",
    "            self._classification_head = self._get_classification_head()\n",
    "            self._regression_head = self._get_regression_head()\n",
    "            \n",
    "            self._classification_logits = []\n",
    "            self._centerness_logits = []\n",
    "            self._regression_logits = []\n",
    "            \n",
    "            for i in range(3, 8):\n",
    "                feature = self._pyramid_features['P{}'.format(i)]\n",
    "                _cls_head_logits = self._classification_head(feature)\n",
    "                _reg_head_logits = self._regression_head(feature)\n",
    "                self._classification_logits.append(_cls_head_logits[0][0])\n",
    "                self._centerness_logits.append(_cls_head_logits[0][1])\n",
    "                self._regression_logits.append(_reg_head_logits)\n",
    "                \n",
    "            _image_input = self._backbone.input\n",
    "            outputs = [self._classification_logits,\n",
    "                       self._centerness_logits, \n",
    "                       self._regression_logits]\n",
    "            self.model = tf.keras.Model(inputs=[_image_input], outputs=outputs, name='FCOS')\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _classification_loss(labels, logits):\n",
    "        #TODO\n",
    "        pass\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _centerness_loss(labels, logits):\n",
    "        #TODO\n",
    "        pass\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _regression_loss(labels, logits):\n",
    "        #TODO\n",
    "        pass\n",
    "    \n",
    "            \n",
    "    @staticmethod\n",
    "    def _per_level_loss(labels, logits):\n",
    "        #TODO\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def _compute_total_loss(labels, logits):\n",
    "        #TODO\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'mode':'train',\n",
    "    'distribute_strategy':tf.distribute.OneDeviceStrategy(device='/cpu:0'),\n",
    "    'image_height':720,\n",
    "    'image_width':1280,\n",
    "    'num_classes':80,\n",
    "    'dataset':None,\n",
    "    'epochs':250,\n",
    "    'learning_rate':1e-4,\n",
    "    'model_dir':'model_files',\n",
    "    'tensorboard_log_dir':'logs'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Building FPN\n",
      "****Building FCOS\n"
     ]
    }
   ],
   "source": [
    "fcos = FCOS(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'classification_head/Identity:0' shape=(None, 90, 160, 80) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_1/Identity:0' shape=(None, 45, 80, 80) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_2/Identity:0' shape=(None, 23, 40, 80) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_3/Identity:0' shape=(None, 12, 20, 80) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_4/Identity:0' shape=(None, 6, 10, 80) dtype=float32>,\n",
       " <tf.Tensor 'classification_head/Identity_1:0' shape=(None, 90, 160, 1) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_1/Identity_1:0' shape=(None, 45, 80, 1) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_2/Identity_1:0' shape=(None, 23, 40, 1) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_3/Identity_1:0' shape=(None, 12, 20, 1) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_4/Identity_1:0' shape=(None, 6, 10, 1) dtype=float32>,\n",
       " <tf.Tensor 'regression_head/Identity:0' shape=(None, 90, 160, 4) dtype=float32>,\n",
       " <tf.Tensor 'regression_head_1/Identity:0' shape=(None, 45, 80, 4) dtype=float32>,\n",
       " <tf.Tensor 'regression_head_2/Identity:0' shape=(None, 23, 40, 4) dtype=float32>,\n",
       " <tf.Tensor 'regression_head_3/Identity:0' shape=(None, 12, 20, 4) dtype=float32>,\n",
       " <tf.Tensor 'regression_head_4/Identity:0' shape=(None, 6, 10, 4) dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcos.model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"regression_head\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, None, None, 256)] 0         \n",
      "_________________________________________________________________\n",
      "r_head_0_conv_3x3 (Conv2D)   multiple                  590080    \n",
      "_________________________________________________________________\n",
      "r_head_0_bn (BatchNormalizat multiple                  1024      \n",
      "_________________________________________________________________\n",
      "r_head_0_relu (ReLU)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "r_head_1_conv_3x3 (Conv2D)   multiple                  590080    \n",
      "_________________________________________________________________\n",
      "r_head_1_bn (BatchNormalizat multiple                  1024      \n",
      "_________________________________________________________________\n",
      "r_head_1_relu (ReLU)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "r_head_2_conv_3x3 (Conv2D)   multiple                  590080    \n",
      "_________________________________________________________________\n",
      "r_head_2_bn (BatchNormalizat multiple                  1024      \n",
      "_________________________________________________________________\n",
      "r_head_2_relu (ReLU)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "r_head_3_conv_3x3 (Conv2D)   multiple                  590080    \n",
      "_________________________________________________________________\n",
      "r_head_3_bn (BatchNormalizat multiple                  1024      \n",
      "_________________________________________________________________\n",
      "r_head_3_relu (ReLU)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "reg_logits_conv_3x3 (Conv2D) multiple                  9220      \n",
      "_________________________________________________________________\n",
      "reg_logits (Lambda)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 2,373,636\n",
      "Trainable params: 2,371,588\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "Model: \"classification_head\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c_head_0_conv_3x3 (Conv2D)      multiple             590080      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "c_head_0_bn (BatchNormalization multiple             1024        c_head_0_conv_3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "c_head_0_relu (ReLU)            multiple             0           c_head_0_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c_head_1_conv_3x3 (Conv2D)      multiple             590080      c_head_0_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c_head_1_bn (BatchNormalization multiple             1024        c_head_1_conv_3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "c_head_1_relu (ReLU)            multiple             0           c_head_1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c_head_2_conv_3x3 (Conv2D)      multiple             590080      c_head_1_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c_head_2_bn (BatchNormalization multiple             1024        c_head_2_conv_3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "c_head_2_relu (ReLU)            multiple             0           c_head_2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "c_head_3_conv_3x3 (Conv2D)      multiple             590080      c_head_2_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "c_head_3_bn (BatchNormalization multiple             1024        c_head_3_conv_3x3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "c_head_3_relu (ReLU)            multiple             0           c_head_3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cls_logits_conv_3x3 (Conv2D)    multiple             184400      c_head_3_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ctr_logits_conv_3x3 (Conv2D)    multiple             2305        c_head_3_relu[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,551,121\n",
      "Trainable params: 2,549,073\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcos._regression_head.summary(), fcos._classification_head.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'classification_head/Identity:0' shape=(None, 90, 160, 80) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_1/Identity:0' shape=(None, 45, 80, 80) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_2/Identity:0' shape=(None, 23, 40, 80) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_3/Identity:0' shape=(None, 12, 20, 80) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_4/Identity:0' shape=(None, 6, 10, 80) dtype=float32>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcos._classification_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'classification_head/Identity_1:0' shape=(None, 90, 160, 1) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_1/Identity_1:0' shape=(None, 45, 80, 1) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_2/Identity_1:0' shape=(None, 23, 40, 1) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_3/Identity_1:0' shape=(None, 12, 20, 1) dtype=float32>,\n",
       " <tf.Tensor 'classification_head_4/Identity_1:0' shape=(None, 6, 10, 1) dtype=float32>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcos._centerness_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'regression_head/Identity:0' shape=(None, 90, 160, 4) dtype=float32>,\n",
       " <tf.Tensor 'regression_head_1/Identity:0' shape=(None, 45, 80, 4) dtype=float32>,\n",
       " <tf.Tensor 'regression_head_2/Identity:0' shape=(None, 23, 40, 4) dtype=float32>,\n",
       " <tf.Tensor 'regression_head_3/Identity:0' shape=(None, 12, 20, 4) dtype=float32>,\n",
       " <tf.Tensor 'regression_head_4/Identity:0' shape=(None, 6, 10, 4) dtype=float32>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcos._regression_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P3': <tf.Tensor 'P3_conv_3x3_1/Identity:0' shape=(None, 90, 160, 256) dtype=float32>,\n",
       " 'P4': <tf.Tensor 'P4_conv_3x3_1/Identity:0' shape=(None, 45, 80, 256) dtype=float32>,\n",
       " 'P5': <tf.Tensor 'P5_conv_3x3_1/Identity:0' shape=(None, 23, 40, 256) dtype=float32>,\n",
       " 'P6': <tf.Tensor 'P6_conv_3x3_1/Identity:0' shape=(None, 12, 20, 256) dtype=float32>,\n",
       " 'P7': <tf.Tensor 'P7_conv_3x3_1/Identity:0' shape=(None, 6, 10, 256) dtype=float32>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcos._pyramid_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FCOS\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 720, 1280, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 726, 1286, 3) 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 360, 640, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 362, 642, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 180, 320, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 180, 320, 64) 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 180, 320, 64) 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 180, 320, 64) 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 180, 320, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 180, 320, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 182, 322, 64) 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 180, 320, 64) 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 180, 320, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 180, 320, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 180, 320, 256 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 180, 320, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 180, 320, 256 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 180, 320, 256 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 180, 320, 256 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 180, 320, 64) 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 180, 320, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 180, 320, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 182, 322, 64) 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 180, 320, 64) 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 180, 320, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 180, 320, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 180, 320, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 180, 320, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 180, 320, 256 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 180, 320, 256 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 180, 320, 64) 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 180, 320, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 180, 320, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 182, 322, 64) 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 90, 160, 64)  36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 90, 160, 64)  256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 90, 160, 64)  0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 90, 160, 256) 0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 90, 160, 256) 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 90, 160, 256) 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 90, 160, 256) 1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 90, 160, 256) 0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 90, 160, 128) 32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 90, 160, 128) 0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 92, 162, 128) 0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 90, 160, 128) 147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 90, 160, 128) 0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 90, 160, 512) 131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 90, 160, 512) 66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 90, 160, 512) 0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 90, 160, 512) 2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 90, 160, 512) 0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 90, 160, 128) 65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 90, 160, 128) 0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 92, 162, 128) 0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 90, 160, 128) 147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 90, 160, 128) 0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 90, 160, 512) 66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 90, 160, 512) 0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 90, 160, 512) 2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 90, 160, 512) 0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 90, 160, 128) 65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 90, 160, 128) 0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 92, 162, 128) 0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 90, 160, 128) 147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 90, 160, 128) 0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 90, 160, 512) 66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 90, 160, 512) 0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 90, 160, 512) 2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 90, 160, 512) 0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 90, 160, 128) 65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 90, 160, 128) 512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 90, 160, 128) 0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 92, 162, 128) 0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 45, 80, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 45, 80, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 45, 80, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 45, 80, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 45, 80, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 45, 80, 512)  0           max_pooling2d_4[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 45, 80, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 45, 80, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 45, 80, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 45, 80, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 45, 80, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 45, 80, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 45, 80, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 45, 80, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 45, 80, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 45, 80, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 45, 80, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 45, 80, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 45, 80, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 45, 80, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 45, 80, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 45, 80, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 45, 80, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 45, 80, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 45, 80, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 45, 80, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 45, 80, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 45, 80, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 45, 80, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 45, 80, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 45, 80, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 45, 80, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 45, 80, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 45, 80, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 45, 80, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 45, 80, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 45, 80, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 45, 80, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 45, 80, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 45, 80, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 45, 80, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 45, 80, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 45, 80, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 45, 80, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 45, 80, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 45, 80, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 45, 80, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 45, 80, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 45, 80, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 45, 80, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 45, 80, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 45, 80, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 47, 82, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 23, 40, 256)  589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 23, 40, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 23, 40, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 23, 40, 1024) 0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 23, 40, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 23, 40, 1024) 0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 23, 40, 1024) 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 23, 40, 1024) 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 23, 40, 512)  524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 23, 40, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 25, 42, 512)  0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 23, 40, 512)  2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 23, 40, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 23, 40, 2048) 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 23, 40, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 23, 40, 2048) 0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 23, 40, 2048) 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 23, 40, 2048) 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 23, 40, 512)  1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 23, 40, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 25, 42, 512)  0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 23, 40, 512)  2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 23, 40, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 23, 40, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 23, 40, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 23, 40, 2048) 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 23, 40, 2048) 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 23, 40, 512)  1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 23, 40, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 25, 42, 512)  0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 23, 40, 512)  2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 23, 40, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 23, 40, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 23, 40, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 23, 40, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 23, 40, 2048) 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 23, 40, 2048) 0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "C5_conv_1x1 (Conv2D)            (None, 23, 40, 256)  524544      post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "C4_conv_1x1 (Conv2D)            (None, 45, 80, 256)  65792       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_M5_upsampled_1/Resi [(None, 45, 80, 256) 0           C5_conv_1x1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "M4_M5_add (Add)                 (None, 45, 80, 256)  0           C4_conv_1x1[0][0]                \n",
      "                                                                 tf_op_layer_M5_upsampled_1/Resize\n",
      "__________________________________________________________________________________________________\n",
      "P5_conv_3x3 (Conv2D)            (None, 23, 40, 256)  590080      C5_conv_1x1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "C3_conv_1x1 (Conv2D)            (None, 90, 160, 256) 33024       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_M4_upsampled_1/Resi [(None, 90, 160, 256 0           M4_M5_add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P6_conv_3x3 (Conv2D)            (None, 12, 20, 256)  590080      P5_conv_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "M3_M4_add (Add)                 (None, 90, 160, 256) 0           C3_conv_1x1[0][0]                \n",
      "                                                                 tf_op_layer_M4_upsampled_1/Resize\n",
      "__________________________________________________________________________________________________\n",
      "P6_relu (ReLU)                  (None, 12, 20, 256)  0           P6_conv_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "P3_conv_3x3 (Conv2D)            (None, 90, 160, 256) 590080      M3_M4_add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P4_conv_3x3 (Conv2D)            (None, 45, 80, 256)  590080      M4_M5_add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "P7_conv_3x3 (Conv2D)            (None, 6, 10, 256)   590080      P6_relu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "classification_head (Model)     multiple             2551121     P3_conv_3x3[0][0]                \n",
      "                                                                 P4_conv_3x3[0][0]                \n",
      "                                                                 P5_conv_3x3[0][0]                \n",
      "                                                                 P6_conv_3x3[0][0]                \n",
      "                                                                 P7_conv_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "regression_head (Model)         multiple             2373636     P3_conv_3x3[0][0]                \n",
      "                                                                 P4_conv_3x3[0][0]                \n",
      "                                                                 P5_conv_3x3[0][0]                \n",
      "                                                                 P6_conv_3x3[0][0]                \n",
      "                                                                 P7_conv_3x3[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 32,063,317\n",
      "Trainable params: 32,013,781\n",
      "Non-trainable params: 49,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fcos.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
